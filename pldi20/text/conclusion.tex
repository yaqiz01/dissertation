\section{Conclusion}
\label{sec:conclusion}
Reconfigurable dataflow accelerators (RDAs) are a promising class of spatial accelerators, which deliver higher performance-to-resource efficiency than conventional process architectures while capturing a large application space.
However, to sustain these benefits as RDAs get larger, the software stack must address the challenges of (a) distributed control / correctness and (b) efficient resource allocation.

We address these challenges by proposing a distributed asynchronous control scheme and a program decomposition method. 
We develop a compiler, \name{}, that constructs a virtual block dataflow graph (VBDFG) from a program specification and generates a minimal set of peer-to-peer synchronizations, which allow fine-grained parallelization factors that would otherwise incur large communication overheads.
Furthermore, operations on VBDFG are decomposed and assigned to a heterogenous collections of physical blocks (PBs). 
Lastly, we implement these techniques and through evaluations show that \name{} achieves a speedup of 4x over a Tesla V100 GPU.
We hope that the approach and implementation presented in this work will help scale modern RDAs add a steady pace..

%\paragraph{Discussion.}
%This work leaves open several tasks: handling programs which are too large to map to a single RDA, and automatic memory sharing. In the case where programs are two large, there are two immediate, orthogonal solutions: time-multiplexing of the RDA via rapid reconfiguration, and splitting the program among multiple RDAs. Automatic memory sharing is a different form of time-multiplexing, allowing a single piece of memory to be used for several time-disjoint tasks. Additionally, as seen in the evaluation, the solver-based methods require substantial optimization to be tractable on complex programs.
