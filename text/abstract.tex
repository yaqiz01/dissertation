\prefacesection{Abstract}

%The rise of ``dark silicon'' in the semiconductor industry due to the end of Dennard scaling 
%started the multicore era in processor design since 2005.
%Nonetheless, the performance scaling in multicores is soon coming to a limit, which motivates a new
%class of spatial architecture--reconfigurable dataflow accelerators (RDAs)--that delivers high throughput 
%and energy efficiency in computation to keep up with the performance demand.
%To adapt to the compute intensity in modern data-analytic workloads, particularly in deep learning, RDAs are increasing to a scale
%that was unprecedented before.
%The increase in scale introduces new challenges in on-chip network design to maintain the energy efficiency and scalability of RDAs.
%Furthermore, managing and using RDAs at this scale also require new strategies in mapping, memory management, and flexible control
%to saturate compute throughput of the accelerator. 

%In this talk, I will talk about architectural design and compilation techinques that improves the scaling efficiency of a RDA developed 
%at Stanford--Plasticine.
%Staring with a static-dynamic hybrid network, we show that the hybrid network can improves energy efficiency while providing
%guaranteed success in placement and routing.
%Next, I will talk about compiler techinques that convert applications' complex control hierarchies, such as nested loops and branch conditions, into a streaming dataflow representation that can be efficiently executed by Plasticine with distributed on-chip resources.
%The compiler implements (a) a peer-to-peer (p2p) control paradigm inferred from an imperative programming style that minimizes synchronization overhead, and (b) a mapping strategy that decomposes the computation and memory in a program across a distributed heterogeneous resources.
%By applying these techniques, we show that Plasticine is able to outperform state of art accelerators, such as GPUs and FPGAs, in
%both performance and performance/Watt in various dense, sparse, and streaming applications.

With the slowdown of Mooreâ€™s Law, specialized hardware accelerators are gaining tractions as energy-efficient platforms that deliver 100-1000x performance improvement over general-purpose processors. 
Reconfigurable architectures are particularly promising in providing high-throughput and low-latency computation in streaming and data-intensive analytics applications. Instead of dynamically executing instructions like in processor architectures, reconfigurable architectures have flexible datapath that can be statically configured to parallelize and/or pipeline the program spatially across on-chip resources. The pipelined execution model and explicitly-managed scratchpad in reconfigurable accelerators dramatically reduce the performance, area, and energy overhead in dynamic execution and conventional cache memory hierarchy, respectively. Plasticine is a hierarchical coarse-grained reconfigurable dataflow accelerator introduced at Stanford in 2017. Compared to fine-grained reconfigurable architecture, like FPGAs, Plasticine has shown 76x performance/watt benefit due to the reduction in routing overhead and the improvement in on-chip resource density. 

In this talk, we will discuss two aspects of the software-hardware codesign that impact the accessibility and performance of the accelerator. One of the biggest challenges that hinders the adoption of these accelerators is the low-level declarative configuration interface that requires the programmers to have detailed knowledge about the underlying microarchitecture implementation and hardware constraints. To address the challenge, I will introduce a compiler stack that provides a high-level programming interface that efficiently translates imperative control constructs to streaming dataflow execution with minimum synchronization overhead on an on-chip distributed architecture. The compiler handles the hardware constraints systematically with resource virtualization. Next, I will present a comprehensive study on the on-chip network design for reconfigurable dataflow architectures that sustain performance in a scalable fashion with high energy efficiency.
